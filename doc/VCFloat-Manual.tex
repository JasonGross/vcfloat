\documentclass{llncs}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{lstlangcoq}
\lstset{language=Coq,basicstyle=\sffamily\small,mathescape=true,columns=fullflexible}
\hyphenation{Comp-Cert}
\pagestyle{plain}

\title{VCFloat 2.0 Reference Manual}
\author{Andrew W. Appel\inst{1} \and Ariel E. Kellison\inst{2}}
\institute{Princeton University \and Cornell University}

\begin{document}
\maketitle

\section{Introduction}
\label{section:Introduction}

VCFloat is a tool for Coq proofs about floating-point round-off error.
When performing a computation such as $x\times 5.7+y$
in floating-point with a fixed number of mantissa bits,
the result of $x\times 5.7$ cannot always be represented exactly
in the same number of bits, ditto the result of the addition $+y$,
so some low-order bits must be thrown away---there is \emph{round-off error}.

We can state this more formally with a bit of notation.
Let \lstinline{%F64} be a notation scope in which
  \lstinline{*} and \lstinline{+} and are interpreted
  as double-precision (64-bit) floating-point operators
  and 5.7 is interpreted as a double-precision floating-point constant;
  let \lstinline{R} be the function that
  injects a floating-point value into the reals.  Then we might prove
  that
\[
\begin{array}{c}
 1 \le x \le 100 \qquad -1000 \le y \le 1000 \\ \hline
 | \mbox{\lstinline{(x*5.7+y)%F64}} - R(x)\times 5.7+R(y) | \le A
\end{array}
\]
where $A$ is an accuracy bound calculated by VCFloat.

When you prove the correctness and accuracy of a numerical program,
there is far more to do than bound the round-off error.
If we view \lstinline{(x*5.7+y)%F64} as a \emph{floating-point functional model}
  of your program, and $R(x)\times 5.7+R(y)$ as a
  \emph{real-valued functional model} of the same program, then
  the main result of interest can be proved by composing
  these three theorems:
\begin{enumerate}
  \item The real-valued functional model finds a solution to
    the mathematical problem of interest, within accuracy bound $A_1$.
  \item The float-valued functional model approximates the
    real-valued functional model within accuracy bound $A_2$.
  \item The program (in C or Python or whatever) correctly implements
    the float-valued functional model.
\end{enumerate}
VCFloat2 provides
\begin{itemize}
\item The \emph{modelling language} for describing float-valued functional
  models and automatically deriving the corresponding real-valued models;
\item A prover for bounding roundoff error, the difference between the two models;
\item Tools for connecting float-valued models to C programs.  But
  in VCFloat 2.0 (unlike in 1.0) the float-valued modeling language
  is quite independent of C and can be used to reason about numerical
  programs in other languages.
\end{itemize}

\section{Floating-point functional models}
Normally to use VCFloat you start with,
\begin{lstlisting}
Require Import VCFloat.VCFloat.
\end{lstlisting}
This imports VCFloat's functional modelling language and all of its
provers.  But in a .v file is you are \emph{only} writing a functional model,
and not using the tools to prove things about it, it will suffice
to import only the modelling language, that is, \lstinline{Require Import VCFloat.FPCore}.

Functional models are written as expressions in Coq that apply
functions (such as \emph{add} and \emph{multiply}) to
variables, constants, and subexpressions that belong to floating-point
\emph{types}.  We will start with the types.

\begin{lstlisting}
type : Type $\mbox{\qquad\emph{each floating-point format is described as a}~\textsf{type}}$
ftype: type -> Type $\mbox{\qquad\emph{a floating-point number in format $\mathsf{t}$ belongs to Coq type} \mathsf{ftype(t)}}$
TYPE : forall (precp : positive) (femax: Z), fprecp<femax -> 1<fprecp -> type.
Tsingle: type := TYPE 24 128 I I.
Tdouble: type := TYPE 53 1024 I I.
\end{lstlisting}

That is, you specify a floating-point format, a \lstinline{type}, by
the number of mantissa bits (e.g., 24 for single-precision, 53 for
double-precision, but any number $\ge 2$ is legal) and a maximum
exponent value (128 for single-precision, 1024 for double-precision,
any number greater than the number of mantissa bits).
\lstinline{TYPE} is a constructor for \lstinline{type}, and the
\lstinline{I} arguments happen to be proofs that \lstinline{24<128}
and \lstinline{1<24}, and so on.

\paragraph{Notation Scopes.}  The notation scope delimiters \%F32 and \%F64 indicate that constants and operator-symbols should stand for single precision and double-precision (respectively) values and functions.
\begin{lstlisting}
Definition myformula ($h$: ftype Tdouble) := 
     (5.0e-1 + cast Tsingle ($h$ * 1.6)%F64)%F32.
\end{lstlisting}
Here, the constant 1.6 and operator \lstinline{*} are
interpreted in double precision,
and the constant 5.0e-1 (which could just as well have been written
as .5) and operator \lstinline{+} are interpreted in single precision.
The variable $h$ is a double-precision floating-point number.

